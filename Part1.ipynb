{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {"pycharm": {"name": "#%% Carvana dataset example\n"}}, "outputs": [], "source": ["import numpy as np\n", "\n", "from transformations import (\n", "    ComposeDouble,\n", "    FunctionWrapperDouble,\n", "    create_dense_target,\n", "    normalize_01,\n", ")\n", "from customdatasets import SegmentationDataSet1\n", "from torch.utils.data import DataLoader\n", "from sklearn.model_selection import train_test_split\n", "import pathlib\n", "\n", "# root directory\n", "root = pathlib.Path.cwd() / \"Carvana\"\n", "\n", "\n", "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n", "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n", "    filenames = [file for file in path.glob(ext) if file.is_file()]\n", "    return filenames\n", "\n", "\n", "# input and target files\n", "inputs = get_filenames_of_path(root / \"Input\")\n", "targets = get_filenames_of_path(root / \"Target\")\n", "\n", "# training transformations and augmentations\n", "transforms = ComposeDouble(\n", "    [\n", "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n", "        FunctionWrapperDouble(\n", "            np.moveaxis, input=True, target=False, source=-1, destination=0\n", "        ),\n", "        FunctionWrapperDouble(normalize_01),\n", "    ]\n", ")\n", "\n", "# random seed\n", "random_seed = 42\n", "\n", "# split dataset into training set and validation set\n", "train_size = 0.8  # 80:20 split\n", "\n", "inputs_train, inputs_valid = train_test_split(\n", "    inputs, random_state=random_seed, train_size=train_size, shuffle=True\n", ")\n", "\n", "targets_train, targets_valid = train_test_split(\n", "    targets, random_state=random_seed, train_size=train_size, shuffle=True\n", ")\n", "\n", "# dataset training\n", "dataset_train = SegmentationDataSet1(\n", "    inputs=inputs_train, targets=targets_train, transform=transforms\n", ")\n", "\n", "# dataset validation\n", "dataset_valid = SegmentationDataSet1(\n", "    inputs=inputs_valid, targets=targets_valid, transform=transforms\n", ")\n", "\n", "# dataloader training\n", "dataloader_training = DataLoader(dataset=dataset_train, batch_size=2, shuffle=True)\n", "\n", "# dataloader validation\n", "dataloader_validation = DataLoader(dataset=dataset_valid, batch_size=2, shuffle=True)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["x, y = next(iter(dataloader_training))\n", "\n", "print(f\"x = shape: {x.shape}; type: {x.dtype}\")\n", "print(f\"x = min: {x.min()}; max: {x.max()}\")\n", "print(f\"y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# create DatasetViewer instances\n", "from visual import DatasetViewer\n", "\n", "dataset_viewer_training = DatasetViewer(dataset_train)\n", "dataset_viewer_validation = DatasetViewer(dataset_valid)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# open napari instance for training dataset\n", "# navigate with 'n' for next and 'b' for back on the keyboard\n", "dataset_viewer_training.napari()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# open napari instance for validation dataset\n", "# navigate with 'n' for next and 'b' for back on the keyboard\n", "dataset_viewer_validation.napari()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import albumentations\n", "from transformations import AlbuSeg2d\n", "\n", "\n", "# training transformations and augmentations\n", "transforms_training = ComposeDouble(\n", "    [\n", "        AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n", "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n", "        FunctionWrapperDouble(\n", "            np.moveaxis, input=True, target=False, source=-1, destination=0\n", "        ),\n", "        FunctionWrapperDouble(normalize_01),\n", "    ]\n", ")\n", "\n", "\n", "# validation transformations\n", "transforms_validation = ComposeDouble(\n", "    [\n", "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n", "        FunctionWrapperDouble(\n", "            np.moveaxis, input=True, target=False, source=-1, destination=0\n", "        ),\n", "        FunctionWrapperDouble(normalize_01),\n", "    ]\n", ")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# dataset training\n", "dataset_train = SegmentationDataSet1(\n", "    inputs=inputs_train, targets=targets_train, transform=transforms_training\n", ")\n", "\n", "# dataset validation\n", "dataset_valid = SegmentationDataSet1(\n", "    inputs=inputs_valid, targets=targets_valid, transform=transforms_validation\n", ")\n", "\n", "# dataloader training\n", "dataloader_training = DataLoader(dataset=dataset_train, batch_size=2, shuffle=True)\n", "\n", "# dataloader validation\n", "dataloader_validation = DataLoader(dataset=dataset_valid, batch_size=2, shuffle=True)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# create DatasetViewer instances\n", "from visual import DatasetViewer\n", "\n", "dataset_viewer_training = DatasetViewer(dataset_train)\n", "dataset_viewer_validation = DatasetViewer(dataset_valid)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# open napari instance for training dataset\n", "# navigate with 'n' for next and 'b' for back on the keyboard\n", "dataset_viewer_training.napari()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# open napari instance for validation dataset\n", "# navigate with 'n' for next and 'b' for back on the keyboard\n", "dataset_viewer_validation.napari()\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.8"}}, "nbformat": 4, "nbformat_minor": 4}