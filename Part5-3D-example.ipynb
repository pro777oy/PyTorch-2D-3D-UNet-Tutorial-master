{"cells": [{"cell_type": "code", "execution_count": null, "id": "d7fe369e-a582-4d99-9d35-bdc5039127b6", "metadata": {}, "outputs": [], "source": ["# Imports\n", "import pathlib\n", "\n", "import albumentations\n", "import numpy as np\n", "import torch\n", "from torch.utils.data import DataLoader\n", "\n", "from customdatasets import SegmentationDataSet3\n", "from transformations import (\n", "    ComposeDouble,\n", "    normalize_01,\n", "    FunctionWrapperDouble,\n", "    create_dense_target,\n", "    AlbuSeg3d,\n", ")\n", "\n", "# root directory\n", "root = pathlib.Path.cwd() / \"Microtubules3D\"\n", "\n", "\n", "def get_filenames_of_path(path: pathlib.Path, ext: str = \"*\"):\n", "    \"\"\"Returns a list of files in a directory/path. Uses pathlib.\"\"\"\n", "    filenames = [file for file in path.glob(ext) if file.is_file()]\n", "    return filenames\n", "\n", "\n", "# input and target files\n", "inputs = get_filenames_of_path(root / \"Input\")\n", "targets = get_filenames_of_path(root / \"Target\")\n", "\n", "# training transformations and augmentations\n", "# example how to properly resize and use AlbuSeg3d\n", "# please note that the input is grayscale and the channel dimension of size 1 is added\n", "# also note that the AlbuSeg3d currently only works with input that does not have a C dim!\n", "transforms_training = ComposeDouble(\n", "    [\n", "        # FunctionWrapperDouble(resize, input=True, target=False, output_shape=(16, 100, 100)),\n", "        # FunctionWrapperDouble(resize, input=False, target=True, output_shape=(16, 100, 100), order=0, anti_aliasing=False, preserve_range=True),\n", "        # AlbuSeg3d(albumentations.HorizontalFlip(p=0.5)),\n", "        # AlbuSeg3d(albumentations.VerticalFlip(p=0.5)),\n", "        # AlbuSeg3d(albumentations.Rotate(p=0.5)),\n", "        AlbuSeg3d(albumentations.RandomRotate90(p=0.5)),\n", "        FunctionWrapperDouble(create_dense_target, input=False, target=True),\n", "        FunctionWrapperDouble(np.expand_dims, axis=0),\n", "        # RandomFlip(ndim_spatial=3),\n", "        FunctionWrapperDouble(normalize_01),\n", "    ]\n", ")\n", "\n", "# random seed\n", "random_seed = 42\n", "\n", "# dataset training\n", "dataset_train = SegmentationDataSet3(\n", "    inputs=inputs,\n", "    targets=targets,\n", "    transform=transforms_training,\n", "    use_cache=False,\n", "    pre_transform=None,\n", ")\n", "\n", "x, y = dataset_train[1]\n", "print(x.shape)\n", "print(x.min(), x.max())\n", "print(y.shape)\n", "print(torch.unique(y))\n", "\n", "# dataloader training\n", "dataloader_training = DataLoader(\n", "    dataset=dataset_train,\n", "    batch_size=1,\n", "    # batch_size of 2 won't work because the depth dimension is different between the 2 samples\n", "    shuffle=True,\n", ")\n", "\n", "batch = next(iter(dataloader_training))\n", "x, y = batch\n", "print(x.shape)\n", "print(x.min(), x.max())\n", "print(y.shape)\n", "print(torch.unique(y))\n", "\n", "# create DatasetViewer instances\n", "from visual import DatasetViewer\n", "\n", "dataset_viewer_training = DatasetViewer(dataset_train)\n", "dataset_viewer_training.napari()  # navigate with 'n' for next and 'b' for back\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.8"}}, "nbformat": 4, "nbformat_minor": 5}